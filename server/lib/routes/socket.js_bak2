// import {Point3} from "../../../opencv4nodejs/lib";

const cv = require('opencv4nodejs'),
    async = require('async'),
    fs = require('fs');

const imgcodecs = require('../processor/imgcodecs');
const img1 = cv.imread('./data/banana.jpg');
// const img2 = cv.imread('./data/br.jpg');
// const img2 = cv.imread('./data/scaled.jpg');
const orbDetector = new cv.SIFTDetector({nFeatures: 500});
const grayimg1 = img1.bgrToGray();
const keyPoints1 = orbDetector.detect(grayimg1);
const descriptors1 = orbDetector.compute(grayimg1, keyPoints1);


//1.相机标定
// 1.1相机内参
const cameraMatrix = new cv.Mat([
    [3215.626082522419, 0, 1471.556444548214],
        [0, 3222.051668804792, 1927.086879135644],
        [0, 0, 1]
], cv.CV_32F);
//1.2相机畸变系数
const distCoeffs = [0.4829911929113178, -2.098554567754686, -0.004550508970407664, -0.003201260898451633, 2.290223376487714];

//2.四个特征点的世界坐标，此处选取的是模板图四个顶点
const patternCorners3D = [
    new cv.Point3(0, 160, 0),
    new cv.Point3(200, 160, 0),
    new cv.Point3(200, 0, 0),
    new cv.Point3(0, 0, 0)
]

// let dstCoordinates;
let rmat;

function codeRotateByZ(point, thetaz) {
    let tx, ty;
    let rz = thetaz * Math.PI / 180;
    tx = Math.cos(rz) * point.x - Math.sin(rz) * point.y;
    ty = Math.sin(rz) * point.x - Math.cos(rz) * point.y;
    return new cv.Point3(tx, ty, point.z)
}

function codeRotateByY(point, thetay) {
    let tx, tz;
    let ry = thetay * Math.PI / 180;
    tx = Math.cos(ry) * point.x - Math.sin(ry) * point.z;
    tz = Math.cos(ry) * point.z - Math.sin(ry) * point.x;
    return new cv.Point3(tx, point.y, tz)
}

function codeRotateByX(point, thetax) {
    let ty, tz;
    let rx = thetax * Math.PI / 180;
    ty = Math.cos(rx) * point.y - Math.sin(rx) * point.z;
    tz = Math.sin(rx) * point.z - Math.cos(rx) * point.y;
    return new cv.Point3(point.x, ty, tz)
}

const matchFeatures = ({img1, img2, detector, matchFunc}) => {
    // let grayimg1=img1.bgrToGray();
    let grayimg2 = img2.bgrToGray();
    // 检测特征点
    // const keyPoints1 = detector.detect(grayimg1);
    const keyPoints2 = detector.detect(grayimg2);

    // 计算特征点描述符
    // const descriptors1 = detector.compute(grayimg1, keyPoints1);
    const descriptors2 = detector.compute(grayimg2, keyPoints2);

    let dstCoordinates;//四个特征点在图像上的对应点坐标，需要与特征点的世界坐标相对应

    try {
        if (descriptors1 && descriptors2) {
            // 特征点匹配
            const matches = matchFunc(descriptors1, descriptors2);


            // only keep good matches
            const bestN = 100;
            const bestMatches = matches.sort(
                (match1, match2) => match1.distance - match2.distance
            ).slice(0, bestN);

            //存放取出的特征点信息
            let points1 = [];
            let points2 = [];
            for (let match of bestMatches) {
                points1.push(keyPoints1[match.queryIdx].point);
                points2.push(keyPoints2[match.trainIdx].point);
            }


            let mask = new cv.Mat();
            //计算img2和img1的单应性变换矩阵homo
            let transform = cv.findHomography(points1, points2, {
                method: cv.RANSAC,
                ransacReprojThreshold: 5,
                mask: mask
            });

            const srcCorners = new cv.Mat([[
                [0, img1.rows],
                [img1.cols, img1.rows],
                [img1.cols, 0],
                [0, 0]
            ]], cv.CV_32FC2);
            dstCoordinates = srcCorners.perspectiveTransform(transform.homography)
        }
        return dstCoordinates;
    } catch (e) {
        return undefined
    }

};
const processBase64 = (base64) => {
    //解码得到视频帧
    let img2 = imgcodecs.decodeFromBase64(base64);
    // let orbMatchesImg = matchFeatures({

    //获取点的世界坐标在图像上的对应点坐标
    let dstPosition = matchFeatures({
        img1,
        img2,
        detector: orbDetector,
        //返回class DescriptorMatch {
        //   readonly queryIdx: number;
        //   readonly trainIdx: number;
        //   readonly distance: number;
        // }
        // matchFunc: cv.matchBruteForceHamming
        matchFunc: cv.matchFlannBased
    });

    // cv.imshowWait('ORB matches', orbMatchesImg);
    return dstPosition;
}

module.exports = function (socket) {
    socket.on('devicemess', function (data) {
        let json = JSON.parse(data);
        //3.四个特征点在图像上的对应点坐标，需要与特征点的世界坐标相对应
        let dstPosition = processBase64(json.imgData);

        if (!dstPosition)
            return;
        let points = [];//存储模板图四个角点的坐标，顺时针存储，返回前端四个点的坐标，用来测试
        let imageCorners = [];//存储模板图四个角点的坐标，顺时针存储
        let pose;

        //将模板图四个顶点在当前帧中的坐标信息进行格式转换，便于下面的计算
        for (let i = 0; i < dstPosition.rows; i++) {
            for (let j = 0; j <= dstPosition.cols - 1; j++) {
                imageCorners.push(
                    new cv.Point2(dstPosition.at(i, j).x, dstPosition.at(i, j).y)
                );
                points.push({
                    x: dstPosition.at(i, j).x,
                    y: dstPosition.at(i, j).y
                })
            }
        }
        let refre_ImagePoints=cv.Mat.eye(4,4,cv.CV_32F);
        if (dstPosition) {

            //4. 求出旋转向量rvec和平移向量tvec
            pose = cv.solvePnP(patternCorners3D, imageCorners, cameraMatrix, distCoeffs);
            // console.log(pose.rvec);
            // console.log(pose.tvec);

            //4.1 根据求出的旋转向量确认下相机坐标系
            let refre_ObjectPoints=[
                new cv.Point3(0,0,0),//空间原点
                new cv.Point3(1,0,0),//x
                new cv.Point3(0,1,0),//y
                new cv.Point3(0,0,1)//z
            ];

            refre_ImagePoints=cv.projectPoints( refre_ObjectPoints, pose.rvec , pose.tvec, cameraMatrix, distCoeffs)

            //由于rodrigues是Mat的方法，需要先将Vec转换成Mat
            let tempMat = new cv.Mat(1, 3, cv.CV_32F);//1x3的矩阵
            tempMat.set(0, 0, pose.rvec.x);
            tempMat.set(0, 1, pose.rvec.y);
            tempMat.set(0, 2, pose.rvec.z);

            //5. 将输出的旋转向量转变为旋转矩阵
            rmat = tempMat.rodrigues();
            // console.log(rmat.dst);//旋转矩阵
            // console.log(rmat.jacobian);//jacobian矩阵

            let r11 = rmat.dst.at(0, 0),
                r21 = rmat.dst.at(1, 0),
                r31 = rmat.dst.at(2, 0),
                r32 = rmat.dst.at(2, 1),
                r33 = rmat.dst.at(2, 2);
            //6. 求出相机的三个旋转角
            let thetaz = Math.atan2(r21, r11) / Math.PI * 180;
            let thetay = Math.atan2(-1 * r31, Math.sqrt(r32 * r32 + r33 * r33)) / Math.PI * 180;
            let thetax = Math.atan2(r32, r33) / Math.PI * 180;
            let rotate = {
                thetax: thetax,
                thetay: thetay,
                thetaz: thetaz,
            }
            console.log(rotate);

            //根据旋转角度求相机在世界坐标系中的位置
            //相机在世界坐标系中的初始位置
            // let p0=new cv.Point3(0,0,50);
            let p0 = new cv.Point3(0, 0, 50);
            let p1 = codeRotateByZ(p0, -thetaz);
            let p2 = codeRotateByY(p1, -thetay);
            let p3 = codeRotateByX(p2, -thetax);

            //世界坐标系中相机的位置坐标为(-p3.x,-p3.y,-p3.z)
            console.log(-p3.x, -p3.y, -p3.z);
        }

        socket.emit('frame', {
            position: points,
            pose: pose,
            refre_ImagePoints:refre_ImagePoints.imagePoints

        });
    })
}